import pandas as pd
import numpy as np
from scipy.stats import mannwhitneyu
import os

# Load the data file
data_path = 'average_depth_per_probe.csv'  # generated by combining results from 4.5 in 4_statistic, each column was labeled with its library and panel (filtered or unfiltered)
data = pd.read_csv(data_path, header=None)

# Data Preprocessing
column_names = data.iloc[0, :]  # First row for library names (e.g., SingleSoilC-Cap)
filter_status = data.iloc[1, :]  # Second row for filter or unfilter status (e.g., filtered)
unique_names = data.iloc[2, :]  # Third row for unique names (e.g., SingleSoilC-Cap-filtered)

# Reshape the data into a long format
long_data = data.iloc[3:].melt(var_name='Column', value_name='Value')  # Reshape to long format
long_data['Sample'] = column_names[long_data['Column']].values  # Add sample names
long_data['Type'] = filter_status[long_data['Column']].values  # Add filter/unfilter status
long_data['UniqueName'] = unique_names[long_data['Column']].values  # Add unique names
long_data['Sample_Type'] = long_data['Sample'] + '-' + long_data['Type']  # Combine sample and type into one column
long_data['Value'] = pd.to_numeric(long_data['Value'], errors='coerce')  # Convert values to numeric, handling errors

# Function to remove outliers using the IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Apply outlier removal to each 'Sample_Type' group
long_data_no_outliers = long_data.groupby('Sample_Type').apply(lambda group: remove_outliers(group, 'Value')).reset_index(drop=True)

# Further group by 'Sample' and 'Type' and remove outliers
df = long_data_no_outliers.groupby(['Sample', 'Type']).apply(lambda x: remove_outliers(x, 'Value')).reset_index(drop=True)

# Mann-Whitney U-test results storage
u_test_results = []

# Perform Mann-Whitney U-test for each sample
for sample in df['Sample'].unique():
    # Get the 'Filter' and 'Unfilter' data
    filter_data = df[(df['Sample'] == sample) & (df['Type'] == 'Filter')]['Value']
    unfilter_data = df[(df['Sample'] == sample) & (df['Type'] == 'Unfilter')]['Value']

    # Perform the Mann-Whitney U test
    stat, p_value = mannwhitneyu(filter_data, unfilter_data, alternative='two-sided')

    # Determine significance levels based on p-value
    if p_value < 0.001:
        significance = '***'
    elif p_value < 0.01:
        significance = '**'
    elif p_value < 0.05:
        significance = '*'
    else:
        significance = ''

    # Save the results
    u_test_results.append({'Sample': sample, 'U Statistic': stat, 'P-Value': p_value, 'Significance': significance})

# Convert results to DataFrame for display
u_test_df = pd.DataFrame(u_test_results)
print(u_test_df)

# Bootstrap analysis
n_bootstraps = 1000  # Number of bootstrap iterations

# Storage for bootstrap results
bootstrap_results = []

# Perform bootstrap analysis for each sample
for sample in df['Sample'].unique():
    # Get 'Filter' and 'Unfilter' data
    filter_data = df[(df['Sample'] == sample) & (df['Type'] == 'Filter')]['Value']
    unfilter_data = df[(df['Sample'] == sample) & (df['Type'] == 'Unfilter')]['Value']

    # Ensure both datasets have the same length by resampling
    min_length = min(len(filter_data), len(unfilter_data))
    filter_data_resampled = filter_data.sample(n=min_length, replace=True)
    unfilter_data_resampled = unfilter_data.sample(n=min_length, replace=True)

    # Bootstrap difference calculations
    boot_diffs = []

    for _ in range(n_bootstraps):
        boot_filter = filter_data_resampled.sample(n=min_length, replace=True)
        boot_unfilter = unfilter_data_resampled.sample(n=min_length, replace=True)
        diff = np.median(boot_filter) - np.median(boot_unfilter)
        boot_diffs.append(diff)

    # Calculate 95% confidence intervals
    ci_lower = np.percentile(boot_diffs, 2.5)
    ci_upper = np.percentile(boot_diffs, 97.5)

    # Calculate p-value as the proportion of differences > 0
    p_value = np.mean(np.array(boot_diffs) > 0)

    # Determine significance levels based on p-value
    if p_value < 0.001:
        significance = '***'
    elif p_value < 0.01:
        significance = '**'
    elif p_value < 0.05:
        significance = '*'
    else:
        significance = ''

    # Save bootstrap results
    bootstrap_results.append({
        'Sample': sample, 
        '95% CI Lower': ci_lower, 
        '95% CI Upper': ci_upper, 
        'P-Value': p_value, 
        'Significance': significance
    })

# Convert bootstrap results to DataFrame for display
bootstrap_df = pd.DataFrame(bootstrap_results)
print(bootstrap_df)
